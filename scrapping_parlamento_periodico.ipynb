{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ursulacotrina/Project01/blob/main/scrapping_parlamento_periodico.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 Install dependencies"
      ],
      "metadata": {
        "id": "PCzazQaQHxY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q pygsheets"
      ],
      "metadata": {
        "id": "I91B0P_mKh7n"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "id": "tKwK7s0BPXFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e7ef3d9-39a9-446a-bcc8-2328f31014bf"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrjgVECYJBIl",
        "outputId": "a3fb0d59-d50c-44ca-9059-f5cb628b3e9d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Levenshtein in /usr/local/lib/python3.10/dist-packages (0.21.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "metadata": {
        "id": "8uVTvy56OHdn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "977d622b-10fa-4187-b544-25c2c2844145"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.10.0)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.26.16)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.22.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.10.3)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2023.5.7)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.4)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.1.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Hit:1 http://deb.debian.org/debian buster InRelease\n",
            "Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:3 http://deb.debian.org/debian buster-updates InRelease\n",
            "Hit:4 http://deb.debian.org/debian-security buster/updates InRelease\n",
            "Hit:5 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:14 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,299 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,360 kB]\n",
            "Fetched 4,995 kB in 3s (1,602 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu0.20.04.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Permite ejecutar comandos de shell directamente en tu entorno de Colab\n",
        "%%shell\n",
        "\n",
        "# Ubuntu no longer distributes chromium-browser outside of snap\n",
        "#\n",
        "# Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap\n",
        "\n",
        "# Add debian buster\n",
        "cat > /etc/apt/sources.list.d/debian.list <<'EOF'\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "EOF\n",
        "\n",
        "# Add keys\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\n",
        "apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "# Prefer debian repo for chromium* packages only\n",
        "# Note the double-blank lines between entries\n",
        "cat > /etc/apt/preferences.d/chromium.pref << 'EOF'\n",
        "Package: *\n",
        "Pin: release a=eoan\n",
        "Pin-Priority: 500\n",
        "\n",
        "\n",
        "Package: *\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 300\n",
        "\n",
        "\n",
        "Package: chromium*\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 700\n",
        "EOF\n",
        "\n",
        "# Install chromium and chromium-driver\n",
        "apt-get update\n",
        "apt-get install chromium\n",
        "\n",
        "# Install xvfb\n",
        "apt install -y xvfb\n",
        "\n",
        "# Install Selenium-Profiles\n",
        "pip uninstall -y selenium_profiles\n",
        "pip install --no-cache-dir selenium_profiles>=2.2.6\n",
        "\n",
        "# pip install https://github.com/kaliiiiiiiiii/Selenium-Profiles/archive/refs/heads/dev.zip # dev-branch\n",
        "\n",
        "# install python packages\n",
        "pip install google-colab-shell\n",
        "pip install webdriver-manager\n",
        "pip install Pyvirtualdisplay"
      ],
      "metadata": {
        "id": "WSXsioNnSck4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b642523e-72c2-4431-d986-d4f09e0d2602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing: /tmp/apt-key-gpghome.F1dqGiJENW/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
            "gpg: key DCC9EFBF77E11517: \"Debian Stable Release Key (10/buster) <debian-release@lists.debian.org>\" not changed\n",
            "gpg: Total number processed: 1\n",
            "gpg:              unchanged: 1\n",
            "Executing: /tmp/apt-key-gpghome.5kEQIEc92j/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
            "gpg: key DC30D7C23CBBABEE: \"Debian Archive Automatic Signing Key (10/buster) <ftpmaster@debian.org>\" not changed\n",
            "gpg: Total number processed: 1\n",
            "gpg:              unchanged: 1\n",
            "Executing: /tmp/apt-key-gpghome.MQyKUOx0Lj/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
            "gpg: key 4DFAB270CAA96DFA: \"Debian Security Archive Automatic Signing Key (10/buster) <ftpmaster@debian.org>\" not changed\n",
            "gpg: Total number processed: 1\n",
            "gpg:              unchanged: 1\n",
            "gpg: cannot open '/dev/tty': No such device or address\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "gpg: [stdout]: write error: Broken pipe\n",
            "gpg: filter_flush failed on close: Broken pipe\n",
            "gpg: cannot open '/dev/tty': No such device or address\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "gpg: [stdout]: write error: Broken pipe\n",
            "gpg: filter_flush failed on close: Broken pipe\n",
            "gpg: cannot open '/dev/tty': No such device or address\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "gpg: [stdout]: write error: Broken pipe\n",
            "gpg: filter_flush failed on close: Broken pipe\n",
            "Hit:1 http://deb.debian.org/debian buster InRelease\n",
            "Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:4 http://deb.debian.org/debian buster-updates InRelease\n",
            "Hit:5 http://deb.debian.org/debian-security buster/updates InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:14 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Fetched 222 kB in 2s (99.8 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium is already the newest version (90.0.4430.212-1~deb10u1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.20.13-1ubuntu1~20.04.8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n",
            "Found existing installation: selenium-profiles 2.2.6\n",
            "Uninstalling selenium-profiles-2.2.6:\n",
            "  Successfully uninstalled selenium-profiles-2.2.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-colab-shell in /usr/local/lib/python3.10/dist-packages (0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 Install Packages"
      ],
      "metadata": {
        "id": "xkMQwXk1IDoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.auth\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import pygsheets\n",
        "credentials, _ = google.auth.default()\n",
        "gc = pygsheets.client.Client(credentials)"
      ],
      "metadata": {
        "id": "MndC8f-7KUfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')"
      ],
      "metadata": {
        "id": "ZRJoUtnGKr5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "import Levenshtein  as lv\n",
        "from itertools import combinations, permutations\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "uyGWs3zkSGdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03 Functions"
      ],
      "metadata": {
        "id": "uxUOnd5lINiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def open_gsheets(link, sheet_index):\n",
        "  sh1 = gc.open_by_url(link)\n",
        "  wks = sh1[sheet_index]\n",
        "  data_get = pd.DataFrame(wks.get_all_records())\n",
        "  return data_get"
      ],
      "metadata": {
        "id": "UxET4-WIHziX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7kEXXOMv1nS"
      },
      "outputs": [],
      "source": [
        "def combinations_string(phrases):\n",
        "  p = phrases.split()\n",
        "  return [\" \".join(a) for a in permutations(p, len(p))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPXxnI-MFg9E"
      },
      "outputs": [],
      "source": [
        "def match_phrases_target(list_1, list_2, nn):\n",
        "  '''\n",
        "  match_phrases_target\n",
        "\n",
        "  Compare all word combinations of phrases versus a string target by Levenshtein algorithm, result is data frame with\n",
        "  list of phrases, list of NN firsts string target more likely to match list of phrases, combination winner and ratio of match\n",
        "  calculated by Levenshtein\n",
        "  '''\n",
        "  r  =pd.DataFrame(columns=['index', 'list_1_phrases', 'list_2_ccpp', 'combination', 'ratio'])\n",
        "  nn = nn\n",
        "  for i in list_1:\n",
        "    #print('frase: ',i)\n",
        "    k = []\n",
        "    for l in list_2:\n",
        "      w=[[],[]]\n",
        "      for j in combinations_string(i):\n",
        "        aa = lv.ratio(j, l)\n",
        "        w[0].append(j)\n",
        "        w[1].append(aa)\n",
        "        #print('ccpp: '+l, 'combinación: '+j, aa)\n",
        "      a_max = max(w[1])\n",
        "      a_max_arg = w[0][w[1].index(max(w[1]))]\n",
        "      k.append([i, l, a_max_arg,a_max])\n",
        "    #print(k)\n",
        "    dd = pd.DataFrame(k, columns=['list_1_phrases', 'list_2_ccpp', 'combination', 'ratio']).sort_values(\n",
        "      by=['list_1_phrases','ratio'], ascending=False).reset_index()[0:nn]\n",
        "    r = r.append(dd, ignore_index=True)\n",
        "  return r"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04 Import data"
      ],
      "metadata": {
        "id": "nXFq6PnwJwdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 04 01 scrapkeys"
      ],
      "metadata": {
        "id": "ADO5H8_2Tgoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "link = 'https://docs.google.com/spreadsheets/d/1FQeZHvmFS5SAIMgGkpP7KNW7CxWu2cP95SkjZqTCh34/edit#gid=0'\n",
        "sheet_index = 0\n",
        "variables1 = open_gsheets(link, sheet_index)\n",
        "variables1"
      ],
      "metadata": {
        "id": "FP-c1aKJJnZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 04 02 Acciones y evaluación"
      ],
      "metadata": {
        "id": "iRaRs_7LTu4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "link = 'https://docs.google.com/spreadsheets/d/1unHBIVHSB_oqrtDQb7bNunzPiC_VT_GDXjzRFyTTyXw/edit#gid=0'\n",
        "sheet_index = 0\n",
        "variables2 = open_gsheets(link, sheet_index)\n",
        "variables2"
      ],
      "metadata": {
        "id": "z9cHP4cWT2Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numbers = variables2['Numero'].tolist()\n",
        "numbers"
      ],
      "metadata": {
        "id": "FfSoMoBcWnXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 04 03 Datos congresistas"
      ],
      "metadata": {
        "id": "Me1hIu2JIDOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "link = 'https://docs.google.com/spreadsheets/d/1BAbFMVPSNuHdj5MaUZqLXgLYN8XA27ERrRbvovVrEHY/edit?usp=drive_web&ouid=117333138354521315740'"
      ],
      "metadata": {
        "id": "RaDwfNsrIAL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sheet_index = 2\n",
        "datoscongresistas = open_gsheets(link, sheet_index)\n",
        "datoscongresistas.head(4)"
      ],
      "metadata": {
        "id": "vmPSBFoVH53y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05 Scrapping"
      ],
      "metadata": {
        "id": "AjkPM4apK_ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "var = variables1['var'][variables1['featurestable']=='features'].tolist()\n",
        "path = variables1['path'][variables1['featurestable']=='features']\n",
        "path14 = variables1['path'][13]\n",
        "\n",
        "estadoscrap = []\n",
        "autorlink = []\n",
        "fecha = []\n",
        "enlace = []\n",
        "vars=[]\n",
        "vars = var + ['estadoscrap', 'autorlink', 'fecha', 'enlace']\n",
        "\n",
        "# Convierte a una lista vacía para cada campo de la lista var\n",
        "for i in var:\n",
        "  globals()[str(i)] = []"
      ],
      "metadata": {
        "id": "ouyNlxq2KP3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar que se tiene una lista vacía para cada campo\n",
        "for i in vars:\n",
        "  print(i, globals()[str(i)])"
      ],
      "metadata": {
        "id": "JL9uThntMnvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parameters\n",
        "\n",
        "dd = pd.DataFrame()\n",
        "ddt = pd.DataFrame()\n",
        "\n",
        "\n",
        "#title Start actual driver\n",
        "from selenium_profiles.webdriver import Chrome\n",
        "from selenium_profiles.profiles import profiles\n",
        "from selenium.webdriver.common.by import By  # locate elements\n",
        "from selenium_profiles.utils.colab_utils import display, showscreen, show_html # virtual display\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "\n",
        "hora_inicio = datetime.now()\n",
        "\n",
        "chromedriver_path = ChromeDriverManager(version=\"90.0.4430.24\").install()\n",
        "\n",
        "profile = profiles.Windows() # or .Android\n",
        "profile[\"cdp\"][\"cores\"] = None # Chrome 90 doesn't allow emulating cores :(driver = mydriver.start(profile, uc_driver=False, executable_path=chromedriver_path)\n",
        "\n",
        "mydriver = Chrome(profile, executable_path=chromedriver_path)\n",
        "\n",
        "display = display()\n",
        "display.start_display()\n",
        "driver = mydriver.start()\n",
        "\n",
        "#Scrap law projects\n",
        "\n",
        "for e in numbers:\n",
        "  #clean\n",
        "  estadoscrap = []\n",
        "  autorlink = []\n",
        "  fecha = []\n",
        "  enlace = []\n",
        "  for i in var:\n",
        "    globals()[str(i)] = []\n",
        "\n",
        "\n",
        "  print(e)\n",
        "  hoy = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "  link = 'https://wb2server.congreso.gob.pe/spley-portal/#/expediente/2021/'+str(e)\n",
        "\n",
        "  fecha.append(hoy)\n",
        "  enlace.append(link)\n",
        "  try:\n",
        "    driver.get(link)  # test client hints\n",
        "    time.sleep(2) # Tiempo de espera de 2s para ejecutar lo siguiente\n",
        "    try:\n",
        "      try:\n",
        "        driver.find_element(By.XPATH,'//*[@id=\"p-fieldset-0-content\"]/div/div[1]/div[9]/ul/li[3]/a[2]').click()\n",
        "      except:\n",
        "        driver.find_element(By.XPATH,'//*[@id=\"p-fieldset-1-content\"]/div/div[1]/div[9]/ul/li[3]/a[2]').click()  #exp 2412\n",
        "    except NoSuchElementException:\n",
        "      print('not button')\n",
        "\n",
        "    try:\n",
        "      try:\n",
        "        autorlin = driver.find_element(By.XPATH,'//*[@id=\"p-fieldset-0-content\"]/div/div[1]/div[8]/ul/li/a').get_attribute('href')\n",
        "      except StaleElementReferenceException:\n",
        "        autorlin = ''\n",
        "\n",
        "      status='no'\n",
        "      autorlink.append(autorlin)\n",
        "\n",
        "      for i,j in zip(var,path):\n",
        "        #fill data into list\n",
        "        try:\n",
        "          globals()[str(i)].append(driver.find_element(By.XPATH,j).text)\n",
        "        except NoSuchElementException:\n",
        "          globals()[str(i)].append('')\n",
        "      status = 'yes'\n",
        "      estadoscrap.append(status)\n",
        "      print('ok')\n",
        "    except NoSuchElementException:\n",
        "      pass\n",
        "    try:\n",
        "      table_element = driver.find_element(By.XPATH,path14)\n",
        "      table_html = table_element.get_attribute('innerHTML')\n",
        "      table_soup = BeautifulSoup(table_html, 'html.parser')\n",
        "      table = table_soup.table\n",
        "      dft = pd.read_html(str(table))[0]\n",
        "      dft['enlace'] = link\n",
        "    except NoSuchElementException:\n",
        "      dft = pd.DataFrame()\n",
        "  except NoSuchElementException:\n",
        "    for i,j in zip(var,path):\n",
        "        globals()[str(i)].append('')\n",
        "    estadoscrap.append(status)\n",
        "    #showscreen(driver)\n",
        "\n",
        "  #Close Driver\n",
        "  # driver.quit()\n",
        "  # display.stop_display()\n",
        "  # time.sleep(2)\n",
        "  #append data to one law project\n",
        "  data_tuples = list(zip(titulo,\n",
        "                        periodo,\n",
        "                        legisla,\n",
        "                        fechapresenta,\n",
        "                        proponente,\n",
        "                        sumilla,\n",
        "                        observaciones,\n",
        "                        autor,\n",
        "                        coautor,\n",
        "                        adherentes,\n",
        "                        grupoparla,\n",
        "                        comisiones,\n",
        "                        ultimoestado,\n",
        "                        estadoscrap,\n",
        "                        autorlink,\n",
        "                        fecha,\n",
        "                        enlace))\n",
        "  #Convert data tuple into dataframe\n",
        "  df = pd.DataFrame(data_tuples, columns=vars) # creates dataframe of each tuple in list\n",
        "    #Append to main data\n",
        "  dd = pd.concat([dd,df], axis=0, ignore_index=True) # Es la hoja \"datoscongreso\"\n",
        "  ddt = pd.concat([ddt,dft], axis=0, ignore_index=True) # Es la hoja \"datoscongresoseguimiento\"\n",
        "\n",
        "print(datetime.now() - hora_inicio)\n",
        "\n",
        "#Close Driver\n",
        "driver.quit()\n",
        "display.stop_display()"
      ],
      "metadata": {
        "id": "WTR3DxkdN4qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ddt['enlace'].value_counts()"
      ],
      "metadata": {
        "id": "mi1I116KYy1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('dd', dd.shape)\n",
        "print('ddt', ddt.shape)"
      ],
      "metadata": {
        "id": "IpQ5_ihwYk2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd"
      ],
      "metadata": {
        "id": "V8oMo6UBCqvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd['periodo'] = dd['periodo'].str.split('\\n',expand=True)[1]\n",
        "dd['comisiones'] = dd['comisiones'].str.split('\\n',expand=True)[1]\n",
        "dd['legisla'] = dd['legisla'].str.split('\\n',expand=True)[1]\n",
        "dd['fechapresenta'] = dd['fechapresenta'].str.split('\\n',expand=True)[1]\n",
        "dd['observaciones'] = dd['observaciones'].str.split('\\n',expand=True)[1]\n",
        "dd['autor'] = dd['autor'].str.split('\\n',expand=True)[1]\n",
        "dd['grupoparla'] = dd['grupoparla'].str.split('\\n',expand=True)[1]\n",
        "dd['ultimoestado'] = dd['ultimoestado'].str.split('\\n',expand=True)[1]"
      ],
      "metadata": {
        "id": "lRm0WL1tDWBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 06 Limpieza"
      ],
      "metadata": {
        "id": "aPzvJD2lE9UZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06 01 Limpieza datos congreso"
      ],
      "metadata": {
        "id": "zs4-Y28bDfLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "has_line_break = dd['coautor'].str.contains('\\n')\n",
        "dd[has_line_break]"
      ],
      "metadata": {
        "id": "fu1wcoW1D9qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd['proponente'] = dd['proponente'].str.split('\\n', expand=True)[1]\n",
        "dd['coautor'] = dd['coautor'].str.split('\\n', expand=True)[1]\n",
        "dd['sumilla'] = dd['sumilla'].str.split('\\n', expand=True)[1]\n",
        "dd['adherentes'] = dd['adherentes'].str.split('\\n', expand=True)[1]\n",
        "dd.head(4)"
      ],
      "metadata": {
        "id": "vl5wMOzLDiF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pkg_resources import DEVELOP_DIST\n",
        "dd['autor'] = dd['autor'].str.upper()\n",
        "dd['autor'] = dd['autor'].str.replace(',','')\n",
        "\n",
        "dd['autor']"
      ],
      "metadata": {
        "id": "aOoATlJMEN6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06 02 Limpieza congreso seguimiento"
      ],
      "metadata": {
        "id": "SND70LqKE0CY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ddt.head()"
      ],
      "metadata": {
        "id": "urRJzv7lEmLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ddt.replace(np.nan, '', inplace = True)"
      ],
      "metadata": {
        "id": "OQ7EMRdhFKxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ddt['FECHA'] = [ x[5:] for x in ddt['FECHA']]\n",
        "ddt['ESTADO PROCESAL'] = [ x[6:] for x in ddt['ESTADO PROCESAL']]\n",
        "ddt['COMISIÓN'] = [ x[8:] for x in ddt['COMISIÓN']]\n",
        "ddt['DETALLE'] = [ x[7:] for x in ddt['DETALLE']]\n",
        "ddt.head()"
      ],
      "metadata": {
        "id": "zOigcaS6FiRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ddt['FECHA'] = pd.to_datetime(ddt['FECHA'], format='%d/%m/%Y')\n",
        "\n",
        "ddt = ddt.sort_values(['enlace', 'FECHA'],\n",
        "              ascending = [True, True])\n",
        "\n",
        "ddt['contador'] = ddt.groupby(['enlace']).cumcount() + 1"
      ],
      "metadata": {
        "id": "x0cxj2_KF09a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#07 Creación nuevas variables"
      ],
      "metadata": {
        "id": "nUMucBP4Gke2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ddt['min']= ddt.groupby(['enlace'])['FECHA'].transform(min)\n",
        "ddt['max']= ddt.groupby(['enlace'])['FECHA'].transform(max)\n",
        "\n",
        "# Obtención de la fecha máxima y mínima\n",
        "\n",
        "ddt['min'] = pd.to_datetime(ddt['min'])\n",
        "ddt['max'] = pd.to_datetime(ddt['max'])\n",
        "\n",
        "# Cálculo del tiempo de duración\n",
        "\n",
        "ddt['dias_proceso'] = (ddt['max'] - ddt['min']).dt.days # dt.days to remove the word \"days\"\n",
        "\n",
        "# Cálculo del número de pasos del proyecto de ley\n",
        "\n",
        "ddt['contador_total']= ddt.groupby(['enlace'])['contador'].transform(max)"
      ],
      "metadata": {
        "id": "3CKDaY_sGfln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación de la variable semanas_proceso:\n",
        "\n",
        "ddt['semanas_proceso'] = ddt['dias_proceso']/140\n",
        "\n",
        "# Creación de variable categórica para los días:\n",
        "\n",
        "'''\n",
        "De 0 a 20 semanas = 1\n",
        "De 20 a 40 semanas = 2\n",
        "y así sucesivamente\n",
        "'''\n",
        "# Redondear hacia arriba para obtener la variable categórica:\n",
        "\n",
        "ddt['semanas_proceso_cat'] = ddt['semanas_proceso'].apply(np.ceil)\n",
        "\n",
        "# Creación de variable categórica para el contador total:\n",
        "\n",
        "ddt['contador_total_cat'] = (ddt['contador_total']/5).apply(np.ceil)"
      ],
      "metadata": {
        "id": "aeLN-csBHBWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación de la variable brecha_fecha:\n",
        "\n",
        "ddt['brecha_fecha'] = (datetime.now() - ddt['max']).dt.days\n",
        "\n",
        "# Creación variable: contador^2\n",
        "\n",
        "ddt['contador2'] = ddt['contador_total']*ddt['contador_total']\n",
        "\n",
        "# Creación variable: dias_proceso^2\n",
        "\n",
        "ddt['dias_proceso2'] = ddt['dias_proceso']*ddt['dias_proceso']"
      ],
      "metadata": {
        "id": "0sRwuogHLQrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 08 Merge"
      ],
      "metadata": {
        "id": "ZYJjwXk_Hrny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.merge(dd, ddt[['contador_total','dias_proceso','enlace','semanas_proceso', 'semanas_proceso_cat', 'contador_total_cat', 'max']].drop_duplicates(subset='enlace', keep='last'), on=\"enlace\", how=\"left\", indicator=True)\n",
        "df"
      ],
      "metadata": {
        "id": "W6nCLwrLHT1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['_merge'], axis=1)"
      ],
      "metadata": {
        "id": "7sRM7neKKKJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge con datos congresistas"
      ],
      "metadata": {
        "id": "uhg2L7BgHtsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_1 = df['autor'].str.replace(',','').unique() #keys\n",
        "list_2 = datoscongresistas['nombre'][(datoscongresistas['nombre']!='') & (datoscongresistas['fin'].str.contains('2026|2027|2028')==True)].unique()\n",
        "\n",
        "bb = match_phrases_target(list_1, list_2, nn = 1)"
      ],
      "metadata": {
        "id": "029v_iU-IpT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('list_1',list_1.shape)\n",
        "print('list_2',list_2.shape)\n",
        "bb"
      ],
      "metadata": {
        "id": "DSTcRUumJPcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bb = bb[['list_1_phrases', 'list_2_ccpp']]\n",
        "bb.columns = ['key_autor', 'key_congresista']\n",
        "bb"
      ],
      "metadata": {
        "id": "AEL0iiOUJd60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.merge(df, bb, left_on=\"autor\", right_on=\"key_autor\", how=\"left\", indicator=True)\n",
        "df1"
      ],
      "metadata": {
        "id": "P3pGChYLJiPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1.drop(['_merge'], axis=1)"
      ],
      "metadata": {
        "id": "Chv8ZYlSK7aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.merge(df1, datoscongresistas[['nombre','votacion','inicio','fin','grupopartido','bancada','representa','condicion']][(datoscongresistas['nombre']!='') & (datoscongresistas['fin'].str.contains('2026|2027|2028')==True)],\n",
        "               left_on=\"key_congresista\", right_on=\"nombre\", how=\"left\", indicator=True)"
      ],
      "metadata": {
        "id": "H1Cc6fftK6pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exportación para ver resultados\n",
        "lin = 'https://docs.google.com/spreadsheets/d/16vsPetGMBsRQfz-jIYL7JL32euMCYA6O8-qA48L4W8U/edit#gid=0'"
      ],
      "metadata": {
        "id": "8ifaKc_EmkYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sh2 = gc.open_by_url(lin)\n",
        "wks1 = sh2[3]\n",
        "wks1.clear(start='A1', end=None)\n",
        "wks1.set_dataframe(df2, 'A1')"
      ],
      "metadata": {
        "id": "Ksqjht_-MR7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Término del script"
      ],
      "metadata": {
        "id": "WwaI1L8nMc-q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}